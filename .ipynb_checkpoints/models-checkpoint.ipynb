{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"ADNIMERGE_train.csv\")\n",
    "df_test = pd.read_csv(\"ADNIMERGE_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other_PI</th>\n",
       "      <th>PTRACCAT_More_than_one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>...</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>WholeBrain_slope</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Entorhinal_slope</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>Fusiform_slope</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>MidTemp_slope</th>\n",
       "      <th>ICV</th>\n",
       "      <th>ICV_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.644830e+05</td>\n",
       "      <td>-1766.049081</td>\n",
       "      <td>2995.000000</td>\n",
       "      <td>-64.791139</td>\n",
       "      <td>14530.000000</td>\n",
       "      <td>-3.466522</td>\n",
       "      <td>14249.000000</td>\n",
       "      <td>-47.827089</td>\n",
       "      <td>1.255450e+06</td>\n",
       "      <td>-0.543778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029740e+06</td>\n",
       "      <td>-865.813171</td>\n",
       "      <td>3522.000000</td>\n",
       "      <td>0.192841</td>\n",
       "      <td>19848.000000</td>\n",
       "      <td>-49.114981</td>\n",
       "      <td>19938.000000</td>\n",
       "      <td>5.985021</td>\n",
       "      <td>1.426170e+06</td>\n",
       "      <td>-497.941640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.113170e+05</td>\n",
       "      <td>-298.923218</td>\n",
       "      <td>3892.000000</td>\n",
       "      <td>-33.188387</td>\n",
       "      <td>18787.000000</td>\n",
       "      <td>-31.965315</td>\n",
       "      <td>18141.000000</td>\n",
       "      <td>-15.742622</td>\n",
       "      <td>1.308120e+06</td>\n",
       "      <td>-150.122005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043388e+06</td>\n",
       "      <td>-824.231999</td>\n",
       "      <td>3576.089971</td>\n",
       "      <td>-8.352327</td>\n",
       "      <td>18087.830383</td>\n",
       "      <td>-32.266216</td>\n",
       "      <td>19935.085546</td>\n",
       "      <td>-32.674813</td>\n",
       "      <td>1.502300e+06</td>\n",
       "      <td>-124.516227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043388e+06</td>\n",
       "      <td>-824.231999</td>\n",
       "      <td>3576.089971</td>\n",
       "      <td>-8.352327</td>\n",
       "      <td>18087.830383</td>\n",
       "      <td>-32.266216</td>\n",
       "      <td>19935.085546</td>\n",
       "      <td>-32.674813</td>\n",
       "      <td>1.762990e+06</td>\n",
       "      <td>-195.973811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RID  DX_bl  PTGENDER  PTEDUCAT  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0  4001      2         0         9               0               0   \n",
       "1  4007      1         1        20               0               0   \n",
       "2  4010      0         0        18               0               0   \n",
       "3  4012      1         0        16               0               0   \n",
       "4  4014      0         1        16               0               0   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other_PI  PTRACCAT_More_than_one  PTRACCAT_Unknown  \\\n",
       "0                           0                       0                 0   \n",
       "1                           0                       0                 0   \n",
       "2                           0                       0                 0   \n",
       "3                           0                       0                 0   \n",
       "4                           0                       0                 0   \n",
       "\n",
       "   PTRACCAT_White     ...        WholeBrain  WholeBrain_slope   Entorhinal  \\\n",
       "0               1     ...      8.644830e+05      -1766.049081  2995.000000   \n",
       "1               1     ...      1.029740e+06       -865.813171  3522.000000   \n",
       "2               1     ...      9.113170e+05       -298.923218  3892.000000   \n",
       "3               1     ...      1.043388e+06       -824.231999  3576.089971   \n",
       "4               1     ...      1.043388e+06       -824.231999  3576.089971   \n",
       "\n",
       "   Entorhinal_slope      Fusiform  Fusiform_slope       MidTemp  \\\n",
       "0        -64.791139  14530.000000       -3.466522  14249.000000   \n",
       "1          0.192841  19848.000000      -49.114981  19938.000000   \n",
       "2        -33.188387  18787.000000      -31.965315  18141.000000   \n",
       "3         -8.352327  18087.830383      -32.266216  19935.085546   \n",
       "4         -8.352327  18087.830383      -32.266216  19935.085546   \n",
       "\n",
       "   MidTemp_slope           ICV   ICV_slope  \n",
       "0     -47.827089  1.255450e+06   -0.543778  \n",
       "1       5.985021  1.426170e+06 -497.941640  \n",
       "2     -15.742622  1.308120e+06 -150.122005  \n",
       "3     -32.674813  1.502300e+06 -124.516227  \n",
       "4     -32.674813  1.762990e+06 -195.973811  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>DX_bl</th>\n",
       "      <th>PTGENDER</th>\n",
       "      <th>PTEDUCAT</th>\n",
       "      <th>PTRACCAT_Asian</th>\n",
       "      <th>PTRACCAT_Black</th>\n",
       "      <th>PTRACCAT_Hawaiian/Other_PI</th>\n",
       "      <th>PTRACCAT_More_than_one</th>\n",
       "      <th>PTRACCAT_Unknown</th>\n",
       "      <th>PTRACCAT_White</th>\n",
       "      <th>...</th>\n",
       "      <th>WholeBrain</th>\n",
       "      <th>WholeBrain_slope</th>\n",
       "      <th>Entorhinal</th>\n",
       "      <th>Entorhinal_slope</th>\n",
       "      <th>Fusiform</th>\n",
       "      <th>Fusiform_slope</th>\n",
       "      <th>MidTemp</th>\n",
       "      <th>MidTemp_slope</th>\n",
       "      <th>ICV</th>\n",
       "      <th>ICV_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043388e+06</td>\n",
       "      <td>-824.231999</td>\n",
       "      <td>3576.089971</td>\n",
       "      <td>-8.352327</td>\n",
       "      <td>18087.830383</td>\n",
       "      <td>-32.266216</td>\n",
       "      <td>19935.085546</td>\n",
       "      <td>-32.674813</td>\n",
       "      <td>1.502300e+06</td>\n",
       "      <td>-124.516227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181170e+06</td>\n",
       "      <td>-945.902809</td>\n",
       "      <td>4405.000000</td>\n",
       "      <td>-1.281092</td>\n",
       "      <td>22968.000000</td>\n",
       "      <td>-44.868160</td>\n",
       "      <td>22654.000000</td>\n",
       "      <td>-40.787854</td>\n",
       "      <td>1.768220e+06</td>\n",
       "      <td>-346.827114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4009</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.109050e+05</td>\n",
       "      <td>-3162.821533</td>\n",
       "      <td>3576.089971</td>\n",
       "      <td>-8.352327</td>\n",
       "      <td>18087.830383</td>\n",
       "      <td>-32.266216</td>\n",
       "      <td>19935.085546</td>\n",
       "      <td>-32.674813</td>\n",
       "      <td>1.338420e+06</td>\n",
       "      <td>-1049.248536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014790e+06</td>\n",
       "      <td>-1593.688209</td>\n",
       "      <td>3576.089971</td>\n",
       "      <td>-8.352327</td>\n",
       "      <td>18087.830383</td>\n",
       "      <td>-32.266216</td>\n",
       "      <td>19935.085546</td>\n",
       "      <td>-32.674813</td>\n",
       "      <td>1.457910e+06</td>\n",
       "      <td>-45.784445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4021</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144970e+06</td>\n",
       "      <td>-1292.760016</td>\n",
       "      <td>3696.000000</td>\n",
       "      <td>-2.131868</td>\n",
       "      <td>20021.000000</td>\n",
       "      <td>-8.977099</td>\n",
       "      <td>20721.000000</td>\n",
       "      <td>-7.563332</td>\n",
       "      <td>1.630490e+06</td>\n",
       "      <td>-160.150043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    RID  DX_bl  PTGENDER  PTEDUCAT  PTRACCAT_Asian  PTRACCAT_Black  \\\n",
       "0  4004      1         0        14               0               0   \n",
       "1  4005      1         1        16               0               0   \n",
       "2  4009      2         1        17               0               0   \n",
       "3  4015      1         0        20               0               0   \n",
       "4  4021      0         1        20               0               1   \n",
       "\n",
       "   PTRACCAT_Hawaiian/Other_PI  PTRACCAT_More_than_one  PTRACCAT_Unknown  \\\n",
       "0                           0                       0                 0   \n",
       "1                           0                       0                 0   \n",
       "2                           0                       0                 0   \n",
       "3                           0                       0                 0   \n",
       "4                           0                       0                 0   \n",
       "\n",
       "   PTRACCAT_White     ...         WholeBrain  WholeBrain_slope   Entorhinal  \\\n",
       "0               1     ...       1.043388e+06       -824.231999  3576.089971   \n",
       "1               1     ...       1.181170e+06       -945.902809  4405.000000   \n",
       "2               1     ...       9.109050e+05      -3162.821533  3576.089971   \n",
       "3               1     ...       1.014790e+06      -1593.688209  3576.089971   \n",
       "4               0     ...       1.144970e+06      -1292.760016  3696.000000   \n",
       "\n",
       "   Entorhinal_slope      Fusiform  Fusiform_slope       MidTemp  \\\n",
       "0         -8.352327  18087.830383      -32.266216  19935.085546   \n",
       "1         -1.281092  22968.000000      -44.868160  22654.000000   \n",
       "2         -8.352327  18087.830383      -32.266216  19935.085546   \n",
       "3         -8.352327  18087.830383      -32.266216  19935.085546   \n",
       "4         -2.131868  20021.000000       -8.977099  20721.000000   \n",
       "\n",
       "   MidTemp_slope           ICV    ICV_slope  \n",
       "0     -32.674813  1.502300e+06  -124.516227  \n",
       "1     -40.787854  1.768220e+06  -346.827114  \n",
       "2     -32.674813  1.338420e+06 -1049.248536  \n",
       "3     -32.674813  1.457910e+06   -45.784445  \n",
       "4      -7.563332  1.630490e+06  -160.150043  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_train = df_train['DX_bl'].copy()\n",
    "X_test = df_test.drop(['RID', 'DX_bl'], axis=1).copy()\n",
    "y_test = df_test['DX_bl'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with l1 penalty train Score:  0.89694041868\n",
      "Logistic Regression with l2 penalty train Score:  0.621578099839\n",
      "Unweighted Logistic Regression with train Score:  0.621578099839\n",
      "Weighted Logistic Regression train Score:  0.481481481481\n",
      "OVR Logistic Regression train Score:  0.621578099839\n",
      "Multinomial Logistic Regression train Score:  0.900161030596\n"
     ]
    }
   ],
   "source": [
    "#l1\n",
    "log_l1 = LogisticRegressionCV(penalty = 'l1', solver = 'liblinear')\n",
    "log_l1.fit(X_train,y_train)\n",
    "\n",
    "#l2\n",
    "log_l2 = LogisticRegressionCV(penalty = 'l2')\n",
    "log_l2.fit(X_train,y_train)\n",
    "\n",
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegressionCV()\n",
    "unweighted_logistic.fit(X_train,y_train)\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegressionCV(class_weight='balanced')\n",
    "weighted_logistic.fit(X_train,y_train)\n",
    "\n",
    "#ovr\n",
    "log_ovr = LogisticRegressionCV(multi_class = 'ovr')\n",
    "log_ovr.fit(X_train,y_train)\n",
    "\n",
    "#multinomial\n",
    "log_multinomial = LogisticRegressionCV(multi_class = 'multinomial', solver = 'newton-cg')\n",
    "log_multinomial.fit(X_train,y_train)\n",
    "multinomial_c = log_multinomial.C_[0]\n",
    "\n",
    "\n",
    "\n",
    "#Computing the score on the train set - \n",
    "print('Logistic Regression with l1 penalty train Score: ',log_l1.score(X_train, y_train))\n",
    "print('Logistic Regression with l2 penalty train Score: ',log_l2.score(X_train, y_train))\n",
    "print('Unweighted Logistic Regression with train Score: ',unweighted_logistic.score(X_train, y_train))\n",
    "print('Weighted Logistic Regression train Score: ',weighted_logistic.score(X_train, y_train))\n",
    "print('OVR Logistic Regression train Score: ',log_ovr.score(X_train, y_train))\n",
    "print('Multinomial Logistic Regression train Score: ',log_multinomial.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with l1 penalty test Score:  0.851851851852\n",
      "Logistic Regression with l2 penalty test Score:  0.592592592593\n",
      "Unweighted Logistic Regression with test Score:  0.592592592593\n",
      "Weighted Logistic Regression test Score:  0.407407407407\n",
      "OVR Logistic Regression test Score:  0.592592592593\n",
      "Multinomial Logistic Regression test Score:  0.858024691358\n"
     ]
    }
   ],
   "source": [
    "#Computing the score on the train set - \n",
    "print('Logistic Regression with l1 penalty test Score: ',log_l1.score(X_test, y_test))\n",
    "print('Logistic Regression with l2 penalty test Score: ',log_l2.score(X_test, y_test))\n",
    "print('Unweighted Logistic Regression with test Score: ',unweighted_logistic.score(X_test, y_test))\n",
    "print('Weighted Logistic Regression test Score: ',weighted_logistic.score(X_test, y_test))\n",
    "print('OVR Logistic Regression test Score: ',log_ovr.score(X_test, y_test))\n",
    "print('Multinomial Logistic Regression test Score: ',log_multinomial.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    test_class0 = model.score(X_test[y_test==0], y_test[y_test==0])\n",
    "    test_class1 = model.score(X_test[y_test==1], y_test[y_test==1])\n",
    "    test_class2 = model.score(X_test[y_test==2], y_test[y_test==2])\n",
    "    return pd.Series([train_acc, test_acc, test_class0, test_class1, test_class2],\n",
    "                    index = ['Train accuracy', 'Test accuracy', \n",
    "                             \"Test accuracy CN\", \"Test accuracy CI\", \"Test accuracy AD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_score = score(log_l1, X_train, y_train, X_test, y_test)\n",
    "l2_score = score(log_l2, X_train, y_train, X_test, y_test)\n",
    "weighted_score = score(weighted_logistic, X_train, y_train, X_test, y_test)\n",
    "unweighted_score = score(unweighted_logistic, X_train, y_train, X_test, y_test)\n",
    "ovr_score = score(log_ovr, X_train, y_train, X_test, y_test)\n",
    "multi_score = score(log_multinomial, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA & QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalization\n",
    "cols_continuous = ['APOE4', 'CSF_ABETA', 'CSF_TAU',  'CSF_PTAU', \n",
    "                   'FDG', 'FDG_slope', 'AV45', 'AV45_slope', 'CDRSB',\n",
    "                   'CDRSB_slope', 'ADAS13', 'ADAS13_slope', 'MMSE', 'MMSE_slope',\n",
    "                   'RAVLT_immediate', 'RAVLT_immediate_slope', 'RAVLT_learning',\n",
    "                   'RAVLT_learning_slope', 'RAVLT_forgetting', 'RAVLT_forgetting_slope',\n",
    "                   'RAVLT_perc_forgetting', 'RAVLT_perc_forgetting_slope', 'MOCA',\n",
    "                   'MOCA_slope', 'EcogPtMem', 'EcogPtMem_slope', 'EcogPtLang',\n",
    "                   'EcogPtLang_slope', 'EcogPtVisspat', 'EcogPtVisspat_slope',\n",
    "                   'EcogPtPlan', 'EcogPtPlan_slope', 'EcogPtOrgan', 'EcogPtOrgan_slope',\n",
    "                   'EcogPtDivatt', 'EcogPtDivatt_slope', 'EcogSPMem', 'EcogSPMem_slope',\n",
    "                   'EcogSPLang', 'EcogSPLang_slope', 'EcogSPVisspat',\n",
    "                   'EcogSPVisspat_slope', 'EcogSPPlan', 'EcogSPPlan_slope', 'EcogSPOrgan',\n",
    "                   'EcogSPOrgan_slope', 'EcogSPDivatt', 'EcogSPDivatt_slope', 'FAQ',\n",
    "                   'FAQ_slope', 'Ventricles', 'Ventricles_slope', 'Hippocampus',\n",
    "                   'Hippocampus_slope', 'WholeBrain', 'WholeBrain_slope', 'Entorhinal',\n",
    "                   'Entorhinal_slope', 'Fusiform', 'Fusiform_slope', 'MidTemp',\n",
    "                   'MidTemp_slope', 'ICV', 'ICV_slope']\n",
    "\n",
    "X_train_std = X_train.copy()\n",
    "X_test_std = X_test.copy()\n",
    "for i in cols_continuous:\n",
    "    col_mean = np.mean(X_train_std[i])\n",
    "    col_sd = np.std(X_train_std[i])\n",
    "    if col_sd < 1e-10*col_mean:\n",
    "        X_train_std.loc[i] = (X_train_std[i]-col_mean)/col_sd\n",
    "        X_test_std.loc[i] = (X_test_std[i]-col_mean)/col_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Train Score:  0.864734299517\n",
      "QDA Train Score:  0.919484702093\n",
      "LDA Test Score:  0.83950617284\n",
      "QDA Test Score:  0.802469135802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "## LDA, QDA (standardization needed)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "lda.fit(X_train_std,y_train)\n",
    "qda.fit(X_train_std,y_train)\n",
    "\n",
    "print('LDA Train Score: ',lda.score(X_train_std,y_train))\n",
    "print('QDA Train Score: ',qda.score(X_train_std,y_train))\n",
    "\n",
    "print('LDA Test Score: ',lda.score(X_test_std,y_test))\n",
    "print('QDA Test Score: ',qda.score(X_test_std,y_test))\n",
    "\n",
    "lda_score = score(lda, X_train_std, y_train, X_test_std, y_test)\n",
    "qda_score = score(qda, X_train_std, y_train, X_test_std, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of neighbours:  37\n",
      "KNN Train Score:  0.566827697262\n",
      "KNN Test Score:  0.592592592593\n"
     ]
    }
   ],
   "source": [
    "max_score = 0\n",
    "max_k = 0 \n",
    "\n",
    "for k in range(1,60):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn_val_score = cross_val_score(knn, X_train, y_train).mean()\n",
    "    if knn_val_score > max_score:\n",
    "        max_k = k\n",
    "        max_score = knn_val_score\n",
    "        \n",
    "knn = KNeighborsClassifier(n_neighbors = max_k)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "print(\"Optimal number of neighbours: \", max_k)\n",
    "print('KNN Train Score: ', knn.score(X_train,y_train))\n",
    "print('KNN Test Score: ', knn.score(X_test,y_test))\n",
    "\n",
    "knn_score = score(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 10\n"
     ]
    }
   ],
   "source": [
    "depth = []\n",
    "for i in range(3,20):\n",
    "    dt = DecisionTreeClassifier(max_depth=i)\n",
    "    # Perform 5-fold cross validation \n",
    "    scores = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "    depth.append((i,scores.mean(), scores.std())) \n",
    "depthvals = [t[0] for t in depth]\n",
    "cvmeans = np.array([t[1] for t in depth])\n",
    "cvstds = np.array([t[2] for t in depth])\n",
    "max_indx = np.argmax(cvmeans)\n",
    "md_best = depthvals[max_indx]\n",
    "print('Best depth:',md_best)\n",
    "dt_best = DecisionTreeClassifier(max_depth=md_best)\n",
    "dt_best.fit(X_train, y_train).score(X_test, y_test)\n",
    "dt_score = score(dt_best, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of trees on test: 32 test score: 0.858024691358 train score: 0.998389694042\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "cv_scores =[]\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "for n_trees in trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n_trees, max_depth=md_best, max_features='auto')\n",
    "    #cv_scores.append(cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, n_jobs=-1))\n",
    "    test_scores.append(metrics.accuracy_score(y_test, rf.fit(X_train, y_train).predict(X_test)))\n",
    "    train_scores.append(metrics.accuracy_score(y_train, rf.fit(X_train, y_train).predict(X_train)))   \n",
    "best = train_scores.index(max(train_scores))\n",
    "#best = cv_scores.index(max(cv_scores))\n",
    "print('best number of trees on test:',2**(best),'test score:',test_scores[best],'train score:',train_scores[best])\n",
    "# print('best number of trees on test:',2**(best),'cv score:',cv_scores[best])\n",
    "\n",
    "rf_best = RandomForestClassifier(n_estimators=2**(best), max_depth=md_best, max_features='auto')\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "rf_score = score(rf_best, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best # of predictors for lr 0.1: 50 test score: 0.882716049383 train score: 0.848631239936\n",
      "best # of predictors for lr 0.5: 50 test score: 0.858024691358 train score: 0.808373590982\n",
      "best # of predictors for lr 5: 50 test score: 0.728395061728 train score: 0.666666666667\n",
      "best learning rate and # of predictors: 0.1 18\n"
     ]
    }
   ],
   "source": [
    "boost_score_small = []\n",
    "boost_tsscore_small = []\n",
    "boost_score = []\n",
    "boost_tsscore = []\n",
    "boost_score_large = []\n",
    "boost_tsscore_large = []\n",
    "for i in range(20, 120, 5):\n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=1e-1)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score_small.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore_small.append(adaboost.score(X_test, y_test))\n",
    "    \n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=0.5)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore.append(adaboost.score(X_test, y_test))\n",
    "    \n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=0.5e1)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score_large.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore_large.append(adaboost.score(X_test, y_test))\n",
    "best_small = boost_score_small.index(max(boost_score_small))\n",
    "print('best # of predictors for lr 0.1:',20+(best+1)*5,'test score:',boost_tsscore_small[best_small],'train score:',boost_score_small[best])\n",
    "\n",
    "best_mid = boost_score.index(max(boost_score))\n",
    "print('best # of predictors for lr 0.5:',20+(best+1)*5,'test score:',boost_tsscore[best_mid],'train score:',boost_score[best])\n",
    "\n",
    "best_large = boost_score_large.index(max(boost_score_large))\n",
    "print('best # of predictors for lr 5:',20+(best+1)*5,'test score:',boost_tsscore_large[best_large],'train score:',boost_score_large[best])\n",
    "\n",
    "learning_rates=[1e-1,0.5,0.5e1]\n",
    "best_train_scores = [boost_score_small[best_small],boost_score[best_mid],boost_score_large[best_large]]\n",
    "best_n_estimators = [best_small,best_mid,best_large]\n",
    "super_best_idx = best_train_scores.index(max(best_train_scores))\n",
    "best_lr = learning_rates[super_best_idx]\n",
    "best_n = best_n_estimators[super_best_idx]\n",
    "print('best learning rate and # of predictors:',best_lr,best_n)\n",
    "\n",
    "adaboost_best = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=best_n, learning_rate=best_lr)\n",
    "adaboost_best.fit(X_train, y_train)\n",
    "\n",
    "adaboost_score = score(adaboost_best, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LDA</th>\n",
       "      <th>Logistic Regression with l1</th>\n",
       "      <th>Logistic Regression with l2</th>\n",
       "      <th>Multinomial</th>\n",
       "      <th>OVR</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Unweighted logistic</th>\n",
       "      <th>Weighted logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train accuracy</th>\n",
       "      <td>0.816425</td>\n",
       "      <td>0.996779</td>\n",
       "      <td>0.566828</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.896940</td>\n",
       "      <td>0.621578</td>\n",
       "      <td>0.900161</td>\n",
       "      <td>0.621578</td>\n",
       "      <td>0.919485</td>\n",
       "      <td>0.991948</td>\n",
       "      <td>0.621578</td>\n",
       "      <td>0.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CN</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CI</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.172043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy AD</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AdaBoost  Decision Tree       KNN       LDA  \\\n",
       "Train accuracy    0.816425       0.996779  0.566828  0.864734   \n",
       "Test accuracy     0.833333       0.888889  0.592593  0.839506   \n",
       "Test accuracy CN  0.595238       0.857143  0.023810  0.714286   \n",
       "Test accuracy CI  0.967742       0.892473  0.989247  0.892473   \n",
       "Test accuracy AD  0.740741       0.925926  0.111111  0.851852   \n",
       "\n",
       "                  Logistic Regression with l1  Logistic Regression with l2  \\\n",
       "Train accuracy                       0.896940                     0.621578   \n",
       "Test accuracy                        0.851852                     0.592593   \n",
       "Test accuracy CN                     0.714286                     0.000000   \n",
       "Test accuracy CI                     0.903226                     0.913978   \n",
       "Test accuracy AD                     0.888889                     0.407407   \n",
       "\n",
       "                  Multinomial       OVR       QDA  Random Forest  \\\n",
       "Train accuracy       0.900161  0.621578  0.919485       0.991948   \n",
       "Test accuracy        0.858025  0.592593  0.802469       0.882716   \n",
       "Test accuracy CN     0.809524  0.000000  0.785714       0.738095   \n",
       "Test accuracy CI     0.860215  0.913978  0.806452       0.956989   \n",
       "Test accuracy AD     0.925926  0.407407  0.814815       0.851852   \n",
       "\n",
       "                  Unweighted logistic  Weighted logistic  \n",
       "Train accuracy               0.621578           0.481481  \n",
       "Test accuracy                0.592593           0.407407  \n",
       "Test accuracy CN             0.000000           0.761905  \n",
       "Test accuracy CI             0.913978           0.172043  \n",
       "Test accuracy AD             0.407407           0.666667  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({'Logistic Regression with l1': l1_score, \n",
    "                         'Logistic Regression with l2': l2_score,\n",
    "                         'Weighted logistic': weighted_score,\n",
    "                         'Unweighted logistic': unweighted_score,\n",
    "                         'OVR': ovr_score,\n",
    "                         'Multinomial': multi_score,\n",
    "                         'KNN': knn_score,\n",
    "                         'LDA': lda_score,\n",
    "                         'QDA': qda_score,\n",
    "                         'Decision Tree': dt_score,\n",
    "                         'Random Forest': rf_score,\n",
    "                         'AdaBoost': adaboost_score})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py:414: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/Users/shiyunqiu/anaconda3/lib/python3.5/site-packages/scipy/optimize/linesearch.py:285: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    }
   ],
   "source": [
    "iterations = 1000\n",
    "boot = np.zeros((X_train.shape[1], iterations))\n",
    "for i in range(iterations):\n",
    "    boot_rows = np.random.choice(range(X_train.shape[0]),\n",
    "                                 size=X_train.shape[0], replace=True)\n",
    "    X_train_boot = X_train.values[boot_rows]\n",
    "    y_train_boot = y_train.values[boot_rows]\n",
    "    model_boot = LogisticRegression(multi_class='multinomial', solver='newton-cg', C=multinomial_c)\n",
    "    model_boot.fit(X_train_boot, y_train_boot)\n",
    "    boot[:,i] = model_boot.coef_[2,:]\n",
    "    \n",
    "boot_ci_upper = np.percentile(boot, 97.5, axis=1)\n",
    "boot_ci_lower = np.percentile(boot, 2.5, axis=1)\n",
    "sig_b_ct = []\n",
    "for i in range(X_train.shape[1]):\n",
    "    if boot_ci_upper[i]<0 or boot_ci_lower[i]>0:\n",
    "        sig_b_ct.append(i)\n",
    "        \n",
    "print(\"Most significant coefficients: \")\n",
    "print(X_train.columns[sig_b_ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_best = DecisionTreeClassifier(max_depth=md_best)\n",
    "dt_best.fit(X_train, y_train)\n",
    "print(dt_best.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
