{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Decision tree, Random forest, Adaboost,\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "data_train = pd.read_csv(\"ADNIMERGE_train.csv\")\n",
    "data_test = pd.read_csv(\"ADNIMERGE_test.csv\")\n",
    "y_train = data_train['DX_bl']\n",
    "X_train = data_train.drop(['RID','DX_bl'],axis=1)\n",
    "y_test = data_test['DX_bl']\n",
    "X_test = data_test.drop(['RID','DX_bl'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decision tree\n",
    "depth = []\n",
    "for i in range(3,20):\n",
    "    dt = DecisionTreeClassifier(max_depth=i)\n",
    "    # Perform 5-fold cross validation \n",
    "    scores = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
    "    depth.append((i,scores.mean(), scores.std())) \n",
    "depthvals = [t[0] for t in depth]\n",
    "cvmeans = np.array([t[1] for t in depth])\n",
    "cvstds = np.array([t[2] for t in depth])\n",
    "max_indx = np.argmax(cvmeans)\n",
    "md_best = depthvals[max_indx]\n",
    "print('Best depth:',md_best)\n",
    "dt_best = DecisionTreeClassifier(max_depth=md_best)\n",
    "dt_best.fit(X_train, y_train).score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best number of trees on test: 16 test score: 0.876543209877 train score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=13, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=16, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest\n",
    "# train_scores = []\n",
    "# test_scores = []\n",
    "# trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "# for n_trees in trees:\n",
    "#     rf = RandomForestClassifier(n_estimators=n_trees, max_depth=md_best, max_features='auto')\n",
    "#     test_scores.append(metrics.accuracy_score(y_test, rf.fit(X_train, y_train).predict(X_test)))\n",
    "#     train_scores.append(metrics.accuracy_score(y_train, rf.fit(X_train, y_train).predict(X_train)))\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "cv_scores =[]\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "for n_trees in trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n_trees, max_depth=md_best, max_features='auto')\n",
    "    #cv_scores.append(cross_val_score(estimator=rf, X=X_train, y=y_train, cv=5, n_jobs=-1))\n",
    "    test_scores.append(metrics.accuracy_score(y_test, rf.fit(X_train, y_train).predict(X_test)))\n",
    "    train_scores.append(metrics.accuracy_score(y_train, rf.fit(X_train, y_train).predict(X_train)))   \n",
    "best = train_scores.index(max(train_scores))\n",
    "#best = cv_scores.index(max(cv_scores))\n",
    "print('best number of trees on test:',2**(best),'test score:',test_scores[best],'train score:',train_scores[best])\n",
    "# print('best number of trees on test:',2**(best),'cv score:',cv_scores[best])\n",
    "\n",
    "rf_best = RandomForestClassifier(n_estimators=2**(best), max_depth=md_best, max_features='auto')\n",
    "rf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best # of predictors for lr 0.1: 45 test score: 0.882716049383 train score: 0.848631239936\n",
      "best # of predictors for lr 0.5: 45 test score: 0.851851851852 train score: 0.837359098229\n",
      "best # of predictors for lr 5: 45 test score: 0.728395061728 train score: 0.682769726248\n",
      "best learning rate and # of predictors: 0.1 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       "          learning_rate=0.1, n_estimators=18, random_state=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adaboost\n",
    "boost_score_small = []\n",
    "boost_tsscore_small = []\n",
    "boost_score = []\n",
    "boost_tsscore = []\n",
    "boost_score_large = []\n",
    "boost_tsscore_large = []\n",
    "for i in range(20, 120, 5):\n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=1e-1)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score_small.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore_small.append(adaboost.score(X_test, y_test))\n",
    "    \n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=0.5)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore.append(adaboost.score(X_test, y_test))\n",
    "    \n",
    "    adaboost = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=i, learning_rate=0.5e1)\n",
    "    adaboost.fit(X_train, y_train)\n",
    "    boost_score_large.append(adaboost.score(X_train, y_train))\n",
    "    boost_tsscore_large.append(adaboost.score(X_test, y_test))\n",
    "best_small = boost_score_small.index(max(boost_score_small))\n",
    "print('best # of predictors for lr 0.1:',20+(best+1)*5,'test score:',boost_tsscore_small[best_small],'train score:',boost_score_small[best])\n",
    "\n",
    "best_mid = boost_score.index(max(boost_score))\n",
    "print('best # of predictors for lr 0.5:',20+(best+1)*5,'test score:',boost_tsscore[best_mid],'train score:',boost_score[best])\n",
    "\n",
    "best_large = boost_score_large.index(max(boost_score_large))\n",
    "print('best # of predictors for lr 5:',20+(best+1)*5,'test score:',boost_tsscore_large[best_large],'train score:',boost_score_large[best])\n",
    "\n",
    "learning_rates=[1e-1,0.5,0.5e1]\n",
    "best_train_scores = [boost_score_small[best_small],boost_score[best_mid],boost_score_large[best_large]]\n",
    "best_n_estimators = [best_small,best_mid,best_large]\n",
    "super_best_idx = best_train_scores.index(max(best_train_scores))\n",
    "best_lr = learning_rates[super_best_idx]\n",
    "best_n = best_n_estimators[super_best_idx]\n",
    "print('best learning rate and # of predictors:',best_lr,best_n)\n",
    "\n",
    "adaboost_best = ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=2), n_estimators=best_n, learning_rate=best_lr)\n",
    "adaboost_best.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SVM\n",
    "# Fit SVM model with C = 1000, linear kernel\n",
    "\n",
    "#kernals = ['linear','poly','rbf','sigmoid']\n",
    "kernals = ['linear']\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "model_svm = svm.SVC(C=1000, kernel='linear')\n",
    "model_svm.fit(X_train, y_train)\n",
    "tr_acc = model_svm.score(X_train, y_train)\n",
    "ts_acc = model_svm.score(X_test, y_test)\n",
    "train_scores.append(tr_acc)\n",
    "test_scores.append(ts_acc)\n",
    "print('train scores:',train_scores)\n",
    "print('test scores:',test_scores)\n",
    "best = test_scores.index(max(test_scores))\n",
    "print('best kernal on test:',kernals[best],'test score:',test_scores[best],'train score:',train_scores[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(model, X_train, y_train, X_test, y_test):\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    test_class0 = model.score(X_test[y_test==0], y_test[y_test==0])\n",
    "    test_class1 = model.score(X_test[y_test==1], y_test[y_test==1])\n",
    "    test_class2 = model.score(X_test[y_test==2], y_test[y_test==2])\n",
    "    return pd.Series([train_acc, test_acc, test_class0, test_class1, test_class2],\n",
    "                    index = ['Train accuracy', 'Test accuracy', \n",
    "                             \"Test accuracy CN\", \"Test accuracy CI\", \"Test accuracy AD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaboost</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train accuracy</th>\n",
       "      <td>0.816425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.858025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CN</th>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy CI</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test accuracy AD</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Adaboost  Decision Tree  Random Forest\n",
       "Train accuracy    0.816425       1.000000       0.995169\n",
       "Test accuracy     0.833333       0.888889       0.858025\n",
       "Test accuracy CN  0.595238       0.857143       0.761905\n",
       "Test accuracy CI  0.967742       0.892473       0.913978\n",
       "Test accuracy AD  0.740741       0.925926       0.814815"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = pd.DataFrame({'Decision Tree': score(dt_best, X_train, y_train, X_test, y_test), \n",
    "                         'Random Forest': score(rf_best, X_train, y_train, X_test, y_test),\n",
    "                         'Adaboost': score(adaboost_best, X_train, y_train, X_test, y_test)\n",
    "                         })\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
